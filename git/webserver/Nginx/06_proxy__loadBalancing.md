## 一 负载均衡与反向代理的理解

#### 1.1 负载均衡概念

负载均衡：多态服务器以平等方式组成一个服务器集合，每台服务器都可以单独对外提供服务，通过某种负载划分技术，将外部发送过来的请求均匀的分配到堆成结构中的某一台服务器上。负载均衡能够平均分配客户请求到服务器的阵列，以解决大量并发访问服务问题。  

#### 1.2 反向代理概念

反向代理：以代理服务器来接收网络上的请求，然后将请求转发给内部网络上的服务器，并将内部服务器返回的结果返回给网络上的客户端。在网络上，对于客户端而言，反向代理服务器就像一个服务器。  

#### 1.3 常见的web负载均衡方法

- 方式一：用户手动选择。比如一些软件下载站，同一个软件给与不同的下载点。  
- 方式二：DNS轮询。对统一主机，添加多条A记录，DNS服务器将解析请求按照A记录的顺序，随机分配到不同的IP上。

方式二虽然初级，但是成本低，可以用于不重要服务，缺点是负载不均衡，因为使用该DNS存在缓存，一旦被使用，则用户在一段时间内访问的web服务器都是同一台。  

#### 1.4 四/七层负载均衡

在开发系统互联模型中（OSI），网络的通信工作分为七层：物理层，数据链路层，网络层，传输层，会话层，表示层，应用层。  

其中第四层传输层：传输层是两台计算机之间进行通信时，第一个端到端的层次，起缓冲作用。当网络层服务质量不能满足要求时，该层提高服务，以满足高层要求，当网络层服务质量较好时，该层只进行较少工作。此外，它还要处理端到端的差错控制和流量控制等，最终为会话提供可靠、无误的数据传输。该层协议包括TCP,UDP,SPX等。 

第七层：应用层，为操作系统或网络应用程序提供访问网络服务的接口，包括文件传输，文件管理，电子邮件等信息处理，常见协议有Telnet，FTP,HTTP，SNMP等。  

现代负载均衡技术通常操作OSI模型中的4，7层。第四层负载均衡将一个网络上的IP映射为多个内部服务器的IP地址，对每次TCP请求动态使用其中一个内部IP地址，以达到负载均衡的目的，第七层负载均衡适用于HTTP服务器，根据HTTP报头执行负载均衡任务。  

负载均衡实践：
- 在硬件层面，可以为第四、七层提供负载均衡交换机 
- 软件层面，四层负载均衡代表作是LVS（可以将请求均衡的转移到不同服务器上，且调度器能自动屏蔽故障服务器）
- 软件曾民，七层负载均衡大多基于HTTP反向代理方式，常见代表作是Nginx，HAProxy等
- 大型应用混合负载均衡，如新浪网，负载均衡同时用到了“多线多地区只能DNS解析，DNS轮训，四/七层负载均衡交换机”等技术，只能DNS解析能够让北京电信用户访问北京电信机房，深圳网通用户解析到深圳网通机房

#### 1.5 反向代理与负载均衡区别

反向代理与负载均衡理解：
- 负载均衡：负载均衡器具备转发功能，将不同的请求抛给对应的服务器
- 反向代理：用户请求负载均衡器，负载均衡器再发出请求获得数据返回给用户，nginx不但负载转发了，还做了代理，所以nginx经常被用来作为反向代理服务器

## 二 反向代理配置

#### 2.1 反向代理简单配置

比如现在有一台服务器，内部启用了一些web服务器，分别位于不同的端口上，那么用户如何通过域名直接访问呢？

![](/images/server/nginx01.png)

在服务器内部，nginx将用户的请求代理给对应的web服务器，web服务器将数据通过nginx传回给客户端，这个过程称之为反向代理。  

简单配置如下：
```
http {
    ...
    upstream web_pools {
        server 10.0.0.9:80 weight=5;        # 端口:80可以省略，weight代表权重
        server 10.0.0.10 weight=5;          # 同上
        server 10.0.0.11 weight backup;     # 如果9和10都宕机，则启用该服务器
    }
    # 指定被负载的server
    server {
        listen 80;
        server_name www.test.com test.com;
        location / {
            root html;
            index.html;
            proxy_pass http://web_pools;
        }
    }
    ...
}
```

注意：
- 一个 upstream可以被多个server使用
- 2000万PV以下的网站都可以使用nginx的负载均衡方式。  
- 有些场合需要保持用户的会话，可以在upstream中添加`ip_hash;`，代表同一个ip被分配到同一服务器，但是此时需要删除`backup`所在行，因为这2个配置会冲突。

#### 2.2 upstream模块

nginx的负载均衡依赖于upstream模块，支持代理方式有：proxy_pass,fastcgi_pass（动态服务器的代理）,memcached_pass（缓存服务器的代理）。  

upstream模块默认算法是wrr(权重轮询：weighted round-robin)。 

常见配置:
| server常用参数 | 参数说明 |
| ------ | ------ |
| server 10.0.10.8:80 | 负载均衡后面的RS配置，可以是IP/域名，高并发场景IP要换成域名，通过DNS做负载均衡 |
| weight | 权重，默认为1，权重越大接收的请求越多 |
| max_fails=2 | 最大尝试失败的次数，默认为1，0表示禁止失败尝试，企业场景：2-3，京东1次，蓝汛10次 | 
| fail_timeout=20s | 失败超时时间，默认是10s，常规业务2-3秒 |
| down | 表示服务器用不可用，配合ip_hash使用 | 

#### 2.3 proxy_pass

`proxy_pass`是upstream实现反向代理的地方，它既可以是个upstream名，也可以是个url。`proxy_pass`依赖于http proxy模块实现，安装nginx时默认就会安装该模块。  

现在的开发基本从程序上实现了动静分离，比如上传走的是upload.test.com,静态文件走的是static.test.com,通过proxy_pass也可以实现动静分离：
```
server {
    listen         80;
    servername     www.test.com;
    location / {
        root     html;
        index.html;
        proxy_pass   http://dynamic_pools;
        include proxy.conf;
    }     
    location /static/ {
        proxy_pass   http://static_pools;
        include   proxy.conf;
    }
}
```

以上方式通过域名来实现静态转发，也可以通过文件后缀名来实现：
```
location ~.*.(gif|jpg|jpeg|png|bmp|css|js|html)$ {
    proxy_pass    http://static_pools;
    include   proxy.conf
}
```

依次类推，在企业级配置中，还可以根据useragent等信息做转发，比如手机用户/IE用户转发到对应页面：
```
location / {
    if ($http_user_agent ~* "MSIE")
    {
        proxy_pass   http://ie_pools
    }
    if ($http_user-agent ~* "iphone")
    {
        proxy_pass   http://iphone_pools
    }
}
```

#### 2.4 Nginx负载均衡策略

Nginx的负载均衡策略可以划分为两大类：
- 内置策略：轮询、加权轮询、IP hash三种
- 扩展策略：url hash、fair等多种策略
  
内置策略会默认被编译进Nginx内核，使用时只需要在Nginx服务器配置中设置相关参数即可，扩展策略不会编译进Nginx内核，需要手动将第三方模块编译到Nginx内核。  

轮询策略最简单，就是将每个前端请求按顺序（时间或者排列次序）逐一分配到不同的后端节点上，同时会自动排除出现问题的后端节点。  

加权轮询策略就是在基本的轮询上考虑各后端节点接受请求的权重，指定各个后端节点被轮询到的几率，适用于后端节点性能不均的情况。  

IP hash策略，是将前端的访问IP进行hash操作，根据hash结果将请求分配给不同的后端节点，可以视为特殊的轮询策略，通过Nginx的实现，每个前端访问IP都会访问固定的一个后端节点。这样做可以比年前端用户在后端多个节点上出现session共享问题。  

`url hash`策略和`IP hash`相近，不同之处是`url hash`是对前端请求的url进行hash操作，优点是：如果后端有缓存服务器，它能够提高缓存效率，同时解决session问题，缺点是，如果后端节点出现异常，则不能自动排除节点。  

`fair`是从另一个角度实现负载均衡：会将前端请求转发到一个最近负载最小的后台节点。判断负载最小的办法：通过后端节点对请求的响应时间判断负载。  

## 三 nginx负载均衡的高可用

nginx相当于web服务器集群的门户，因此，Nginx的高可用性对整个web服务来说，异常重要。 

双机高可用一般通过虚拟IP实现（即linux的IP别名）。

#### 3.1 双机高可用方式一

为一台主服务器加一台热备服务器，正常情况下，主服务器绑定一个公网虚拟IP，提供负载均衡服务，热备服务器处于空闲状态，当主服务器发生故障时，热备服务器接管主服务器的虚拟IP，提供负载均衡服务。  

该方式非常常见，但是始终有一台服务器处于空闲状态，浪费了一台服务器的负载均衡处理能力。  

步骤：  
- www.test.com域名解析到虚拟IP 61.1.1.2 上，主机 61.1.1.4 绑定虚拟IP 61.1.1.2
```
/sbin/ifconfig eth0: 61.1.1.2 broadcast 61.1.1.255 netmask 255.255.255.0 up
/sbin/route add -host 61.1.1.2 dev eth0:1
/sbin/arping -I eth0 -c 3 -s 61.1.1.2 61.1.1.1
```
- 此时用户访问 www.test.com（虚拟IP61.1.1.2），实际访问的是主机61.1.1.4，备机61.1.1.5处于空闲状态，若发生故障，则61.1.1.5在几秒钟内接管虚拟IP61.1.1.2，与自己绑定，并发送ARPing包给IDC的公网网关刷新MAC地址：
```
/sbin/ifconfig eth0: 61.1.1.2 broadcast 61.1.1.255 netmask 255.255.255.0 up
/sbin/route add -host 61.1.1.2 dev eth0:1
/sbin/arping -I eth0 -c 3 -s 61.1.1.2 61.1.1.1
```

上述方式可以使用Keepalived软件来实现（内部基于VRRP路由协议）。  

#### 3.2 双机高可用方式二

两台负载均衡服务器各自绑定一个公网虚拟IP，二者现在都可以处于活动状态，提供负载均衡服务，当其中一台服务器发生故障时，另一台服务器接管发生故障服务器的虚拟IP。  

该方式相较于第一种方式多使用了一个公网IP。  

步骤：
- www.test.com域名通过DNS轮训解析到虚拟IP61.1.1.2和61.1.1.3上
- 正常情况下，服务器1：61.1.1.4 绑定虚拟IP61.1.1.2，服务器2：61.1.1.5 绑定虚拟IP61.1.1.3
- 服务器1执行：
```
/sbin/ifconfig eth0: 61.1.1.2 broadcast 61.1.1.255 netmask 255.255.255.0 up
/sbin/route add -host 61.1.1.2 dev eth0:1
/sbin/arping -I eth0 -c 3 -s 61.1.1.2 61.1.1.1
```
- 服务器2执行：
```
/sbin/ifconfig eth0: 61.1.1.3 broadcast 61.1.1.255 netmask 255.255.255.0 up
/sbin/route add -host 61.1.1.3 dev eth0:1
/sbin/arping -I eth0 -c 3 -s 61.1.1.3 61.1.1.1
```